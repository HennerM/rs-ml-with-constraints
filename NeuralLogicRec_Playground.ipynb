{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import utils.common\n",
    "import evaluation\n",
    "import importlib\n",
    "import numpy as np\n",
    "import time\n",
    "from models.ConstraintAutoRec import ConstraintAutoRec \n",
    "import models.NeuralLogicRec\n",
    "import tensorflow as tf\n",
    "importlib.reload(utils.common)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(models.NeuralLogicRec)\n",
    "\n",
    "ml_small = utils.common.ml_small\n",
    "\n",
    "ev = evaluation.Evaluation(ml_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlr = models.NeuralLogicRec.NLR(ml_small['user'], ml_small['dimensions'], epochs=10, embedding_dim =16, batch_size=32768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-15-09528fbea869>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-09528fbea869>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    nlr.train(utils.common.load_dataset(ml_small), ml_small['train']['records'])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# for i in range(16):\n",
    "    nlr.train(utils.common.load_dataset(ml_small), ml_small['train']['records'])\n",
    "#     if i % 3 == 0:\n",
    "#         print(ev.evaluate(nlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(np.flip(np.sort(nlr.predict_single_user(0))))\n",
    "# print(nlr.predict_single_user(1))\n",
    "# nlr.model(np.array(1), np.array(1))\n",
    "user = 0\n",
    "nr_items = 300\n",
    "items = np.arange(nr_items)\n",
    "user = np.repeat(user, nr_items)\n",
    "predictions = nlr.model(user, items)\n",
    "# print(np.argsort(predictions['rec']))\n",
    "rec = models.NeuralLogicRec.map_inference(nlr.model, predictions, 1e-7)['rec']\n",
    "print(np.flip(np.argsort(rec.numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016378402709960938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=31067, shape=(100, 10379), dtype=float32, numpy=\n",
       "array([[0.5694533 , 0.13775632, 0.49378046, ..., 0.5057949 , 0.25483745,\n",
       "        0.39902782],\n",
       "       [0.46809456, 0.49024305, 0.30403072, ..., 0.50656164, 0.20648018,\n",
       "        0.2585095 ],\n",
       "       [0.43638322, 0.46086782, 0.28419387, ..., 0.4452408 , 0.39058134,\n",
       "        0.10435161],\n",
       "       ...,\n",
       "       [0.23576966, 0.7498334 , 0.48725432, ..., 0.6465069 , 0.58142596,\n",
       "        0.29925084],\n",
       "       [0.56220907, 0.41362143, 0.27198112, ..., 0.5033615 , 0.5706911 ,\n",
       "        0.16064787],\n",
       "       [0.5042612 , 0.48036385, 0.5557404 , ..., 0.41024628, 0.3461521 ,\n",
       "        0.362366  ]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "# a = nlr.predict(np.zeros([100, 10379]), np.arange(100))\n",
    "b = model.predict(np.zeros([100, 10379]), np.arange(100))\n",
    "print(time.time() - start)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 8s 415ms/step - loss: 0.2585 - accuracy: 0.0017\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1820 - accuracy: 0.0052\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1653 - accuracy: 0.0128\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1514 - accuracy: 0.0091\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1417 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.1394 - accuracy: 0.0146\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1317 - accuracy: 0.0219\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.1214 - accuracy: 0.0109\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1201 - accuracy: 0.0247\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1093 - accuracy: 0.0263\n"
     ]
    }
   ],
   "source": [
    "model = models.ConstraintAutoRec.ConstraintAutoRec(ml_small['dimensions'], epochs=10, novelty_weight=0.1, diversity_weight=0.1, latent_dim=64)\n",
    "model.train(utils.common.load_dataset(ml_small), ml_small['train']['records'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch nr 1 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating ConstraintAutoRec |============================================================>| 100.0% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6771545827633378,\n",
       " 'precision': 0.9000520562207184,\n",
       " 'recall': 0.6968964127367997,\n",
       " 'map@1': 0.17647058823529413,\n",
       " 'map@5': 0.07030812324929972,\n",
       " 'map@10': 0.05313946213405997,\n",
       " 'diversity@5': 0.22656476412105434,\n",
       " 'diversity@10': 0.2510991474911737,\n",
       " 'epc@5': 0.7065703788244254,\n",
       " 'epc@10': 0.7296286836020914,\n",
       " 'epd@5': 0.31544423568944513,\n",
       " 'name': 'ConstraintAutoRec',\n",
       " 'dimensions': 10379,\n",
       " 'latent_dims': 64,\n",
       " 'accuracy_weight': 1.0,\n",
       " 'novelty_weight': 0.1,\n",
       " 'diversity_weight': 0.1,\n",
       " 'epochs': 10,\n",
       " 'batch_size': 32,\n",
       " 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch nr 1 predicted\n",
      "waiting for queue\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7a6e0079d749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/e/owncloud/FH/MasterThesis/Code/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'waiting for queue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unfinished_tasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_semlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/multiprocessing/synchronize.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;31m# wait for notification or timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_semaphore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;31m# indicate that this thread has woken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ev.evaluate(nlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flip(np.argsort(nlr.predict_single_user(80)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlr.model.user_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable(initial_value=tf.random.normal([1]))\n",
    "b = tf.Variable(initial_value=tf.random.normal([1]))\n",
    "tf.stack([a,b],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_max(a, axis=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_2args(X,Y):\n",
    "    if X.doms == [] and Y.doms == []:\n",
    "        result = tf.concat([X,Y],axis=-1)\n",
    "        result.doms = []\n",
    "        return result,[X,Y]\n",
    "    X_Y = set(X.doms) - set(Y.doms)\n",
    "    Y_X = set(Y.doms) - set(X.doms)\n",
    "    eX = X\n",
    "    eX_doms = [x for x in X.doms]\n",
    "    for y in Y_X:\n",
    "        eX = tf.expand_dims(eX,0)\n",
    "        eX_doms = [y] + eX_doms\n",
    "    eY = Y\n",
    "    eY_doms = [y for y in Y.doms]\n",
    "    for x in X_Y:\n",
    "        eY = tf.expand_dims(eY,-2)\n",
    "        eY_doms.append(x)\n",
    "    perm_eY = []\n",
    "    for y in eY_doms:\n",
    "        perm_eY.append(eX_doms.index(y))\n",
    "    eY = tf.transpose(eY,perm=perm_eY + [len(perm_eY)])\n",
    "    mult_eX = [1]*(len(eX_doms)+1)\n",
    "    mult_eY = [1]*(len(eY_doms)+1)\n",
    "    for i in range(len(mult_eX)-1):\n",
    "        mult_eX[i] = tf.maximum(1,tf.math.floordiv(tf.shape(eY)[i],tf.shape(eX)[i]))\n",
    "        mult_eY[i] = tf.maximum(1,tf.math.floordiv(tf.shape(eX)[i],tf.shape(eY)[i]))\n",
    "    result1 = tf.tile(eX,mult_eX)\n",
    "    result2 = tf.tile(eY,mult_eY)\n",
    "    result = tf.concat([result1,result2],axis=-1)\n",
    "    result1.doms = eX_doms\n",
    "    result2.doms = eX_doms\n",
    "    result.doms = eX_doms\n",
    "    return result,[result1,result2]\n",
    "\n",
    "a.doms = [\"a\"]\n",
    "b.doms = [\"b\"]\n",
    "result, _ = cross_2args(a,b )\n",
    "r_and = tf.reduce_mean(result, axis=2, keepdims=True)\n",
    "print(a)\n",
    "print(b)\n",
    "print(result)\n",
    "print(r_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = (a,b )\n",
    "ax = [result.doms.index(var.doms[0]) for var in vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(r_and, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.convert_to_tensor([300,100, 200], dtype=tf.int32)\n",
    "b = tf.convert_to_tensor(np.arange(20), dtype=tf.int32)\n",
    "user = tf.tile(a, b.shape)\n",
    "items = tf.sort(tf.tile(b, a.shape))\n",
    "# result = user + items\n",
    "print(user)\n",
    "print(items)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nlr.model(user, items)['rec']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.transpose(tf.reshape(result, [20,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
