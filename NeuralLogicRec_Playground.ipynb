{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import utils.common\n",
    "import evaluation\n",
    "import importlib\n",
    "import numpy as np\n",
    "import time\n",
    "from models.ConstraintAutoRec import ConstraintAutoRec \n",
    "import models.NeuralLogicRec\n",
    "import tensorflow as tf\n",
    "importlib.reload(utils.common)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(models.NeuralLogicRec)\n",
    "\n",
    "ml_small = utils.common.ml_small\n",
    "\n",
    "ev = evaluation.Evaluation(ml_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlr = models.NeuralLogicRec.NLR(ml_small['user'], ml_small['dimensions'], epochs=1, embedding_dim =16, batch_size=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 Loss at step 150: -0.7621, time: 16.390\n",
      "Batch nr 1 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.7657318741450069, 'precision': 0.8401515151515152, 'recall': 0.8939943571140669, 'map@1': 0.0, 'map@5': 0.0, 'map@10': 0.00017740429505135386, 'diversity@5': 0.36739639648057176, 'diversity@10': 0.3597071330029012, 'epc@5': 0.9889630940375962, 'epc@10': 0.9852763009762958, 'epd@5': 0.377995229968082, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 1, 'batch_size': 1200}\n",
      "Epoch #0 Loss at step 150: -3.0551, time: 24.577\n",
      "Epoch #0 Loss at step 150: -4.6955, time: 23.992\n",
      "Epoch #0 Loss at step 150: -6.2466, time: 23.907\n",
      "Batch nr 1 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.746922024623803, 'precision': 0.8388478007006618, 'recall': 0.8686013704151552, 'map@1': 0.0, 'map@5': 0.004201680672268907, 'map@10': 0.0021008403361344537, 'diversity@5': 0.3641698809965621, 'diversity@10': 0.3585504087694536, 'epc@5': 0.9869984032535254, 'epc@10': 0.9852646192424193, 'epd@5': 0.3753071977461219, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 1, 'batch_size': 1200}\n",
      "Epoch #0 Loss at step 150: -7.9611, time: 24.459\n",
      "Epoch #0 Loss at step 150: -9.4981, time: 24.859\n",
      "Epoch #0 Loss at step 150: -10.7515, time: 24.071\n",
      "Batch nr 1 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.7435020519835841, 'precision': 0.840882237101221, 'recall': 0.860540104796453, 'map@1': 0.0, 'map@5': 0.0, 'map@10': 9.337068160597572e-05, 'diversity@5': 0.3667998173899022, 'diversity@10': 0.36392833094338445, 'epc@5': 0.9900819545943882, 'epc@10': 0.9875866498694661, 'epd@5': 0.3785262987380919, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 1, 'batch_size': 1200}\n",
      "Epoch #0 Loss at step 150: -12.2791, time: 25.561\n",
      "Epoch #0 Loss at step 150: -13.7848, time: 25.238\n",
      "Epoch #0 Loss at step 150: -15.6329, time: 24.888\n",
      "Batch nr 1 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.75, 'precision': 0.8407320872274143, 'recall': 0.8702136235388956, 'map@1': 0.0, 'map@5': 0.0, 'map@10': 0.00012004801920768306, 'diversity@5': 0.36237437899658925, 'diversity@10': 0.35781289217295414, 'epc@5': 0.9880094877125858, 'epc@10': 0.9864492377734094, 'epd@5': 0.3793227142662957, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 1, 'batch_size': 1200}\n",
      "Epoch #0 Loss at step 150: -16.5813, time: 25.116\n",
      "Epoch #0 Loss at step 150: -18.1632, time: 25.418\n",
      "Epoch #0 Loss at step 150: -19.5619, time: 26.066\n",
      "Batch nr 1 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.7568399452804377, 'precision': 0.8422273781902552, 'recall': 0.8778718258766627, 'map@1': 0.0, 'map@5': 0.0003361344537815126, 'map@10': 0.0003081232492997199, 'diversity@5': 0.36308569624721926, 'diversity@10': 0.35633961360087896, 'epc@5': 0.9883089996344848, 'epc@10': 0.9871413641481553, 'epd@5': 0.37950439363326877, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 1, 'batch_size': 1200}\n",
      "Epoch #0 Loss at step 150: -21.2257, time: 25.883\n",
      "Epoch #0 Loss at step 150: -21.8710, time: 25.114\n",
      "Epoch #0 Loss at step 150: -24.3472, time: 26.518\n",
      "Batch nr 1 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.7688098495212038, 'precision': 0.8430254656024325, 'recall': 0.8939943571140669, 'map@1': 0.0, 'map@5': 0.0013165266106442578, 'map@10': 0.000938375350140056, 'diversity@5': 0.36129712199799097, 'diversity@10': 0.3546210916231688, 'epc@5': 0.9883175976129461, 'epc@10': 0.9864780689104211, 'epd@5': 0.38127513514205036, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 1, 'batch_size': 1200}\n"
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "    nlr.train(utils.common.load_dataset(ml_small), ml_small['train']['records'])\n",
    "    if i % 3 == 0:\n",
    "        print(ev.evaluate(nlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257 151 216 117 299  25 265 246 222 211 210 159 119  50 207 173 115 143\n",
      " 155  11  98  92  96  95  94 100 101  93  99  97 138  91  90  89 103  88\n",
      "  87  86  85  84  83  82  81  80  79  78 102 108 104 130 124 125 126 127\n",
      " 128 129 131 105 132 133 134 135 139 136 123 122 121 120 118 140 116 114\n",
      " 113 112 111 110  77 141 137 107 106 109  73  76  37  20  21  22  23  24\n",
      "  26  27  28  29  30  31  32  33  34  35  19  18  17   7   1   2   3   4\n",
      "   5   6   8  16   9  10  12  13  14  15  36  38  75  39  59  60  61  62\n",
      "  63  64  65  66  67  68  69  70  71  72  74  58  57  56  46  40  41  42\n",
      "  43  44  45  47  55  48  49  51  52  53  54 142 149 144 252 245 247 248\n",
      " 249 250 251 253 243 254 255 256 258 259 260 244 242 262 233 227 228 229\n",
      " 230 231 232 234 241 235 236 237 238 239 240 261 263 225 290 284 285 286\n",
      " 287 288 289 291 282 292 293 294 295 296 297 283 281 264 272 266 267 268\n",
      " 269 270 271 273 280 274 275 276 277 278 279 226 224 145 174 167 168 169\n",
      " 170 171 172 175 165 176 177 178 179 180 181 166 164 183 153 146 147 148\n",
      " 298 150 152 154 163 156 157 158 160 161 162 182 184 223 213 204 205 206\n",
      " 208 209 212 214 202 215 217 218 219 220 221 203 201 185 192 186 187 188\n",
      " 189 190 191 193 200 194 195 196 197 198 199   0]\n"
     ]
    }
   ],
   "source": [
    "# print(np.flip(np.sort(nlr.predict_single_user(0))))\n",
    "# print(nlr.predict_single_user(1))\n",
    "# nlr.model(np.array(1), np.array(1))\n",
    "user = 0\n",
    "nr_items = 300\n",
    "items = np.arange(nr_items)\n",
    "user = np.repeat(user, nr_items)\n",
    "predictions = nlr.model(user, items)\n",
    "# print(np.argsort(predictions['rec']))\n",
    "rec = models.NeuralLogicRec.map_inference(nlr.model, predictions, 1e-7)['rec']\n",
    "print(np.flip(np.argsort(rec.numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch nr 1 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3751709986320109,\n",
       " 'precision': 0.7961956521739131,\n",
       " 'recall': 0.3542926239419589,\n",
       " 'map@1': 0.0,\n",
       " 'map@5': 0.0005602240896358543,\n",
       " 'map@10': 0.00028011204481792715,\n",
       " 'diversity@5': 0.38642315238836494,\n",
       " 'diversity@10': 0.3854676574970965,\n",
       " 'epc@5': 0.9917035977133284,\n",
       " 'epc@10': 0.9912749935746786,\n",
       " 'epd@5': 0.38612166561005457,\n",
       " 'name': 'NeuralLogicRec',\n",
       " 'latent_dim': 128,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 1200}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.evaluate(nlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 8s 436ms/step - loss: 0.2566 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1744 - accuracy: 0.0128\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1639 - accuracy: 0.0411\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1483 - accuracy: 0.0263\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1424 - accuracy: 0.0190\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.1410 - accuracy: 0.0173\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.1322 - accuracy: 0.0260\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.1257 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.1170 - accuracy: 0.0033\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.1127 - accuracy: 0.0016\n"
     ]
    }
   ],
   "source": [
    "model = models.ConstraintAutoRec.ConstraintAutoRec(ml_small['dimensions'], epochs=10, novelty_weight=0.1, diversity_weight=0.1, latent_dim=64)\n",
    "model.train(utils.common.load_dataset(ml_small), ml_small['train']['records'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch nr 1 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating ConstraintAutoRec |============================================================>| 100.0% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6822845417236663,\n",
       " 'precision': 0.8947100712105799,\n",
       " 'recall': 0.7089883111648528,\n",
       " 'map@1': 0.12605042016806722,\n",
       " 'map@5': 0.05232492997198879,\n",
       " 'map@10': 0.0429851504093701,\n",
       " 'diversity@5': 0.23787031282623874,\n",
       " 'diversity@10': 0.2646920640131162,\n",
       " 'epc@5': 0.7503029009116576,\n",
       " 'epc@10': 0.7542414115926078,\n",
       " 'epd@5': 0.3190622687929619,\n",
       " 'name': 'ConstraintAutoRec',\n",
       " 'dimensions': 10379,\n",
       " 'latent_dims': 64,\n",
       " 'accuracy_weight': 1.0,\n",
       " 'novelty_weight': 0.1,\n",
       " 'diversity_weight': 0.1,\n",
       " 'epochs': 10,\n",
       " 'batch_size': 32,\n",
       " 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch nr 1 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.1515047879616963,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'map@1': 0.0,\n",
       " 'map@5': 0.0,\n",
       " 'map@10': 0.00030345471521942105,\n",
       " 'diversity@5': 0.35353541499577024,\n",
       " 'diversity@10': 0.34548889740582156,\n",
       " 'epc@5': 0.9922690114451876,\n",
       " 'epc@10': 0.9906619756357248,\n",
       " 'epd@5': 0.3830725399040539,\n",
       " 'name': 'NeuralLogicRec',\n",
       " 'latent_dim': 128,\n",
       " 'epochs': 50,\n",
       " 'batch_size': 1000}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.evaluate(nlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2804, 3923, 5677, ..., 1019, 1335, 7248]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.flip(np.argsort(nlr.predict_single_user(80)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14283369, shape=(8,), dtype=float32, numpy=\n",
       "array([-0.25685114,  1.1030787 , -0.83440006,  1.078066  ,  0.05426935,\n",
       "       -0.895161  ,  1.4823135 , -0.9063508 ], dtype=float32)>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlr.model.user_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=82112920, shape=(2,), dtype=float32, numpy=array([0.8852266, 1.1255649], dtype=float32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable(initial_value=tf.random.normal([1]))\n",
    "b = tf.Variable(initial_value=tf.random.normal([1]))\n",
    "tf.stack([a,b],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8026786, shape=(3,), dtype=float32, numpy=array([ 3.1626284 , -0.2083571 ,  0.41710454], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(a, axis=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[ 3.1626284 ],\n",
      "       [-0.2083571 ],\n",
      "       [ 0.41710454]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[-0.15450539],\n",
      "       [ 2.0219426 ],\n",
      "       [-0.45979235]], dtype=float32)>\n",
      "tf.Tensor(\n",
      "[[[ 3.1626284  -0.15450539]\n",
      "  [-0.2083571  -0.15450539]\n",
      "  [ 0.41710454 -0.15450539]]\n",
      "\n",
      " [[ 3.1626284   2.0219426 ]\n",
      "  [-0.2083571   2.0219426 ]\n",
      "  [ 0.41710454  2.0219426 ]]\n",
      "\n",
      " [[ 3.1626284  -0.45979235]\n",
      "  [-0.2083571  -0.45979235]\n",
      "  [ 0.41710454 -0.45979235]]], shape=(3, 3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 1.5040615 ]\n",
      "  [-0.18143123]\n",
      "  [ 0.13129959]]\n",
      "\n",
      " [[ 2.5922856 ]\n",
      "  [ 0.90679276]\n",
      "  [ 1.2195235 ]]\n",
      "\n",
      " [[ 1.351418  ]\n",
      "  [-0.33407474]\n",
      "  [-0.0213439 ]]], shape=(3, 3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def cross_2args(X,Y):\n",
    "    if X.doms == [] and Y.doms == []:\n",
    "        result = tf.concat([X,Y],axis=-1)\n",
    "        result.doms = []\n",
    "        return result,[X,Y]\n",
    "    X_Y = set(X.doms) - set(Y.doms)\n",
    "    Y_X = set(Y.doms) - set(X.doms)\n",
    "    eX = X\n",
    "    eX_doms = [x for x in X.doms]\n",
    "    for y in Y_X:\n",
    "        eX = tf.expand_dims(eX,0)\n",
    "        eX_doms = [y] + eX_doms\n",
    "    eY = Y\n",
    "    eY_doms = [y for y in Y.doms]\n",
    "    for x in X_Y:\n",
    "        eY = tf.expand_dims(eY,-2)\n",
    "        eY_doms.append(x)\n",
    "    perm_eY = []\n",
    "    for y in eY_doms:\n",
    "        perm_eY.append(eX_doms.index(y))\n",
    "    eY = tf.transpose(eY,perm=perm_eY + [len(perm_eY)])\n",
    "    mult_eX = [1]*(len(eX_doms)+1)\n",
    "    mult_eY = [1]*(len(eY_doms)+1)\n",
    "    for i in range(len(mult_eX)-1):\n",
    "        mult_eX[i] = tf.maximum(1,tf.math.floordiv(tf.shape(eY)[i],tf.shape(eX)[i]))\n",
    "        mult_eY[i] = tf.maximum(1,tf.math.floordiv(tf.shape(eX)[i],tf.shape(eY)[i]))\n",
    "    result1 = tf.tile(eX,mult_eX)\n",
    "    result2 = tf.tile(eY,mult_eY)\n",
    "    result = tf.concat([result1,result2],axis=-1)\n",
    "    result1.doms = eX_doms\n",
    "    result2.doms = eX_doms\n",
    "    result.doms = eX_doms\n",
    "    return result,[result1,result2]\n",
    "\n",
    "a.doms = [\"a\"]\n",
    "b.doms = [\"b\"]\n",
    "result, _ = cross_2args(a,b )\n",
    "r_and = tf.reduce_mean(result, axis=2, keepdims=True)\n",
    "print(a)\n",
    "print(b)\n",
    "print(result)\n",
    "print(r_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = (a,b )\n",
    "ax = [result.doms.index(var.doms[0]) for var in vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8027635, shape=(1,), dtype=float32, numpy=array([0.7965035], dtype=float32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(r_and, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
