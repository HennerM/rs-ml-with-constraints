{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = list() \n",
    "ae_evals = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import utils.common\n",
    "import evaluation\n",
    "import importlib\n",
    "import numpy as np\n",
    "import time\n",
    "from models.ConstraintAutoRec import ConstraintAutoRec \n",
    "import models.NeuralLogicRec\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from models.NeuralLogicRec import item_cf, user_cf, diversity_constraint, Constraint, And, Or, Implies, Forall, Not, Equiv\n",
    "importlib.reload(utils.common)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(models.NeuralLogicRec)\n",
    "\n",
    "import itertools\n",
    "\n",
    "ml_small = utils.common.ml_small\n",
    "ml_big = utils.common.movie_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Constraint(weight=0.25, formula=<tensorflow.python.eager.def_function.Function object at 0x7fa7901b6630>),\n",
       " Constraint(weight=1.0, formula=<tensorflow.python.eager.def_function.Function object at 0x7fa78d90db70>),\n",
       " Constraint(weight=0.8, formula=<tensorflow.python.eager.def_function.Function object at 0x7fa7a153e208>),\n",
       " Constraint(weight=0.25, formula=<tensorflow.python.eager.def_function.Function object at 0x7fa7a153e128>),\n",
       " Constraint(weight=0.75, formula=<tensorflow.python.eager.def_function.Function object at 0x7fa7a06783c8>)]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints = list()\n",
    "constraints.append(Constraint(weight=0.25, formula=item_cf))\n",
    "constraints.append(Constraint(weight=1.0, formula=user_cf))\n",
    "@tf.function\n",
    "def likes_equiv(model, outputs):\n",
    "    return Forall(Equiv(outputs['rec'], outputs['likes']))\n",
    "constraints.append(Constraint(weight=0.8, formula=likes_equiv))\n",
    "@tf.function\n",
    "def novelty_constraint(model, outputs):\n",
    "    return Forall(Implies(outputs['popular'], Not(outputs['rec'])))\n",
    "constraints.append(Constraint(weight=0.25, formula=novelty_constraint))\n",
    "constraints.append(Constraint(weight=0.75, formula=diversity_constraint))\n",
    "constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ev = evaluation.Evaluation(ml_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlr_ae = models.NeuralLogicRec.NLR(ml_small['user'], ml_small['dimensions'], mode='ae', name='AE_div20sh', epochs=5, embedding_dim=40, batch_size=24, nr_hidden_layers=3, nr_item_samples = 4096, constraints=constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Loss at step 349: 0.1923, time: 33.868. Train P@1 0.007 P@5 0.011, Eval P@1 0.000 P@5 0.001\n",
      "Epoch #2 Loss at step 349: 0.1392, time: 29.257. Train P@1 0.146 P@5 0.139, Eval P@1 0.007 P@5 0.007\n",
      "Epoch #3 Loss at step 349: 0.1233, time: 29.263. Train P@1 0.201 P@5 0.246, Eval P@1 0.007 P@5 0.014\n",
      "Epoch #4 Loss at step 349: 0.1183, time: 29.085. Train P@1 0.306 P@5 0.301, Eval P@1 0.014 P@5 0.019\n",
      "Epoch #5 Loss at step 349: 0.1148, time: 29.381. Train P@1 0.319 P@5 0.306, Eval P@1 0.021 P@5 0.011\n",
      "Batch nr 13 predicted\r"
     ]
    }
   ],
   "source": [
    "nlr_ae.train(utils.common.load_dataset(ml_small), ml_small['train']['records'])\n",
    "ae_evals.append(ev.evaluate_single_thread(nlr_ae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlr_new = models.NeuralLogicRec.NLR(ml_small['user'], ml_small['dimensions'], mode='v2', name='V2_N025_D075_out', epochs=10, embedding_dim=40, batch_size=24, nr_hidden_layers=3, nr_item_samples = 10_000, constraints=constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Loss at step 349: 0.1701, time: 25.702. Train P@1 0.208 P@5 0.185, Eval P@1 0.000 P@5 0.013\n",
      "Epoch #2 Loss at step 349: 0.1233, time: 20.000. Train P@1 0.344 P@5 0.387, Eval P@1 0.021 P@5 0.017\n",
      "Epoch #3 Loss at step 349: 0.1140, time: 19.911. Train P@1 0.573 P@5 0.452, Eval P@1 0.010 P@5 0.029\n",
      "Epoch #4 Loss at step 349: 0.1090, time: 19.869. Train P@1 0.531 P@5 0.483, Eval P@1 0.010 P@5 0.029\n",
      "Epoch #5 Loss at step 349: 0.1055, time: 20.075. Train P@1 0.510 P@5 0.440, Eval P@1 0.031 P@5 0.035\n",
      "Epoch #6 Loss at step 349: 0.1029, time: 20.324. Train P@1 0.500 P@5 0.450, Eval P@1 0.010 P@5 0.021\n",
      "Epoch #7 Loss at step 349: 0.1008, time: 19.753. Train P@1 0.521 P@5 0.498, Eval P@1 0.031 P@5 0.025\n",
      "Epoch #8 Loss at step 349: 0.0984, time: 19.713. Train P@1 0.406 P@5 0.387, Eval P@1 0.000 P@5 0.015\n",
      "Epoch #9 Loss at step 349: 0.0972, time: 19.786. Train P@1 0.406 P@5 0.440, Eval P@1 0.073 P@5 0.023\n",
      "Epoch #10 Loss at step 349: 0.0953, time: 19.653. Train P@1 0.521 P@5 0.440, Eval P@1 0.031 P@5 0.038\n",
      "Batch nr 13 predicted\r"
     ]
    }
   ],
   "source": [
    "nlr_new.train(utils.common.load_dataset(ml_small), ml_small['train']['records'])\n",
    "ae_evals.append(ev.evaluate_single_thread(nlr_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = models.ConstraintAutoRec.ConstraintAutoRec(ml_small['dimensions'], epochs=10, novelty_weight=0.75, diversity_weight=0.75, name='ConstraintAutoRec_N075_D075')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 14s 746ms/step - loss: 0.2436 - accuracy: 0.0016\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2095 - accuracy: 0.0016\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2078 - accuracy: 0.0082\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2080 - accuracy: 0.0049\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2047 - accuracy: 0.0148\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2002 - accuracy: 0.0066\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.1998 - accuracy: 0.0049\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.1955 - accuracy: 0.0049\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.1968 - accuracy: 0.0164\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.1963 - accuracy: 0.0099\n",
      "Batch nr 13 predicted\r"
     ]
    }
   ],
   "source": [
    "car.train(utils.common.load_dataset(ml_small), ml_small['train']['records'])\n",
    "ae_evals.append(ev.evaluate_single_thread(car))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision@5</th>\n",
       "      <th>map@1</th>\n",
       "      <th>map@5</th>\n",
       "      <th>map@10</th>\n",
       "      <th>diversity@5</th>\n",
       "      <th>diversity@10</th>\n",
       "      <th>epc@5</th>\n",
       "      <th>epc@10</th>\n",
       "      <th>epd@5</th>\n",
       "      <th>coverage@1</th>\n",
       "      <th>coverage@5</th>\n",
       "      <th>coverage@10</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118299</td>\n",
       "      <td>0.138016</td>\n",
       "      <td>0.076476</td>\n",
       "      <td>0.063892</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.839210</td>\n",
       "      <td>0.841383</td>\n",
       "      <td>0.159020</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.048261</td>\n",
       "      <td>0.074367</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.177103</td>\n",
       "      <td>0.181647</td>\n",
       "      <td>0.947601</td>\n",
       "      <td>0.943642</td>\n",
       "      <td>0.171897</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>0.022156</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022921</td>\n",
       "      <td>0.028343</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.154523</td>\n",
       "      <td>0.161315</td>\n",
       "      <td>0.941178</td>\n",
       "      <td>0.942126</td>\n",
       "      <td>0.167028</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.028417</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.154036</td>\n",
       "      <td>0.189772</td>\n",
       "      <td>0.105494</td>\n",
       "      <td>0.083369</td>\n",
       "      <td>0.113045</td>\n",
       "      <td>0.128833</td>\n",
       "      <td>0.633749</td>\n",
       "      <td>0.661420</td>\n",
       "      <td>0.151949</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.018592</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.154405</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>0.105062</td>\n",
       "      <td>0.085711</td>\n",
       "      <td>0.112687</td>\n",
       "      <td>0.126375</td>\n",
       "      <td>0.639377</td>\n",
       "      <td>0.669451</td>\n",
       "      <td>0.150891</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.011271</td>\n",
       "      <td>0.020229</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.153913</td>\n",
       "      <td>0.182378</td>\n",
       "      <td>0.103851</td>\n",
       "      <td>0.084182</td>\n",
       "      <td>0.114962</td>\n",
       "      <td>0.125772</td>\n",
       "      <td>0.668409</td>\n",
       "      <td>0.694873</td>\n",
       "      <td>0.150068</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.016954</td>\n",
       "      <td>0.029959</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.158842</td>\n",
       "      <td>0.203943</td>\n",
       "      <td>0.110223</td>\n",
       "      <td>0.087918</td>\n",
       "      <td>0.117859</td>\n",
       "      <td>0.127593</td>\n",
       "      <td>0.661247</td>\n",
       "      <td>0.687662</td>\n",
       "      <td>0.151883</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>0.024082</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.150339</td>\n",
       "      <td>0.175601</td>\n",
       "      <td>0.100489</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>0.118068</td>\n",
       "      <td>0.129446</td>\n",
       "      <td>0.639319</td>\n",
       "      <td>0.668453</td>\n",
       "      <td>0.153940</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.011078</td>\n",
       "      <td>0.022060</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.165003</td>\n",
       "      <td>0.199014</td>\n",
       "      <td>0.110928</td>\n",
       "      <td>0.089545</td>\n",
       "      <td>0.115360</td>\n",
       "      <td>0.124318</td>\n",
       "      <td>0.740063</td>\n",
       "      <td>0.760826</td>\n",
       "      <td>0.150171</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>0.043637</td>\n",
       "      <td>0.067527</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.169070</td>\n",
       "      <td>0.205176</td>\n",
       "      <td>0.115598</td>\n",
       "      <td>0.092897</td>\n",
       "      <td>0.114370</td>\n",
       "      <td>0.123962</td>\n",
       "      <td>0.714903</td>\n",
       "      <td>0.736431</td>\n",
       "      <td>0.150075</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>0.039881</td>\n",
       "      <td>0.066853</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.164633</td>\n",
       "      <td>0.195933</td>\n",
       "      <td>0.112756</td>\n",
       "      <td>0.091934</td>\n",
       "      <td>0.115658</td>\n",
       "      <td>0.124343</td>\n",
       "      <td>0.743881</td>\n",
       "      <td>0.760968</td>\n",
       "      <td>0.150097</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>0.045949</td>\n",
       "      <td>0.072825</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.169070</td>\n",
       "      <td>0.207640</td>\n",
       "      <td>0.114828</td>\n",
       "      <td>0.092392</td>\n",
       "      <td>0.111643</td>\n",
       "      <td>0.122752</td>\n",
       "      <td>0.729649</td>\n",
       "      <td>0.749089</td>\n",
       "      <td>0.149486</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.039592</td>\n",
       "      <td>0.064541</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.078743</td>\n",
       "      <td>0.077018</td>\n",
       "      <td>0.044914</td>\n",
       "      <td>0.040270</td>\n",
       "      <td>0.138219</td>\n",
       "      <td>0.141831</td>\n",
       "      <td>0.898378</td>\n",
       "      <td>0.897465</td>\n",
       "      <td>0.160432</td>\n",
       "      <td>0.043830</td>\n",
       "      <td>0.120701</td>\n",
       "      <td>0.173008</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.171041</td>\n",
       "      <td>0.218731</td>\n",
       "      <td>0.121545</td>\n",
       "      <td>0.098995</td>\n",
       "      <td>0.121382</td>\n",
       "      <td>0.129155</td>\n",
       "      <td>0.748632</td>\n",
       "      <td>0.770310</td>\n",
       "      <td>0.149960</td>\n",
       "      <td>0.018206</td>\n",
       "      <td>0.055101</td>\n",
       "      <td>0.092091</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.160690</td>\n",
       "      <td>0.198398</td>\n",
       "      <td>0.109538</td>\n",
       "      <td>0.090368</td>\n",
       "      <td>0.125102</td>\n",
       "      <td>0.132677</td>\n",
       "      <td>0.771944</td>\n",
       "      <td>0.790142</td>\n",
       "      <td>0.151507</td>\n",
       "      <td>0.027647</td>\n",
       "      <td>0.089972</td>\n",
       "      <td>0.144302</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.173383</td>\n",
       "      <td>0.223044</td>\n",
       "      <td>0.121525</td>\n",
       "      <td>0.101693</td>\n",
       "      <td>0.123560</td>\n",
       "      <td>0.131110</td>\n",
       "      <td>0.753833</td>\n",
       "      <td>0.772850</td>\n",
       "      <td>0.152130</td>\n",
       "      <td>0.020518</td>\n",
       "      <td>0.058376</td>\n",
       "      <td>0.095848</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.117190</td>\n",
       "      <td>0.142945</td>\n",
       "      <td>0.077055</td>\n",
       "      <td>0.062324</td>\n",
       "      <td>0.118228</td>\n",
       "      <td>0.125124</td>\n",
       "      <td>0.627615</td>\n",
       "      <td>0.645038</td>\n",
       "      <td>0.155018</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.008092</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.168207</td>\n",
       "      <td>0.223660</td>\n",
       "      <td>0.119350</td>\n",
       "      <td>0.097883</td>\n",
       "      <td>0.120342</td>\n",
       "      <td>0.128665</td>\n",
       "      <td>0.752063</td>\n",
       "      <td>0.770449</td>\n",
       "      <td>0.151292</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>0.052018</td>\n",
       "      <td>0.087660</td>\n",
       "      <td>NeuralLogicRec_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.174985</td>\n",
       "      <td>0.202095</td>\n",
       "      <td>0.119716</td>\n",
       "      <td>0.099546</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.128802</td>\n",
       "      <td>0.751926</td>\n",
       "      <td>0.768161</td>\n",
       "      <td>0.151063</td>\n",
       "      <td>0.017821</td>\n",
       "      <td>0.048358</td>\n",
       "      <td>0.078220</td>\n",
       "      <td>NeuralLogicRec_V2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.162046</td>\n",
       "      <td>0.202711</td>\n",
       "      <td>0.111448</td>\n",
       "      <td>0.090889</td>\n",
       "      <td>0.121806</td>\n",
       "      <td>0.130240</td>\n",
       "      <td>0.758690</td>\n",
       "      <td>0.777696</td>\n",
       "      <td>0.151526</td>\n",
       "      <td>0.022445</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.120123</td>\n",
       "      <td>NeuralLogicRec_V2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.154775</td>\n",
       "      <td>0.192853</td>\n",
       "      <td>0.106720</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.127122</td>\n",
       "      <td>0.134270</td>\n",
       "      <td>0.769263</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.152851</td>\n",
       "      <td>0.027550</td>\n",
       "      <td>0.089201</td>\n",
       "      <td>0.146518</td>\n",
       "      <td>NeuralLogicRec_V2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.170548</td>\n",
       "      <td>0.204559</td>\n",
       "      <td>0.116194</td>\n",
       "      <td>0.095004</td>\n",
       "      <td>0.122166</td>\n",
       "      <td>0.130144</td>\n",
       "      <td>0.781983</td>\n",
       "      <td>0.795550</td>\n",
       "      <td>0.152038</td>\n",
       "      <td>0.020711</td>\n",
       "      <td>0.057413</td>\n",
       "      <td>0.090261</td>\n",
       "      <td>NeuralLogicRec_V2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.149476</td>\n",
       "      <td>0.197166</td>\n",
       "      <td>0.103886</td>\n",
       "      <td>0.084971</td>\n",
       "      <td>0.126812</td>\n",
       "      <td>0.132980</td>\n",
       "      <td>0.830198</td>\n",
       "      <td>0.834548</td>\n",
       "      <td>0.154223</td>\n",
       "      <td>0.025913</td>\n",
       "      <td>0.063963</td>\n",
       "      <td>0.098545</td>\n",
       "      <td>NeuralLogicRec_V2_nov08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.105360</td>\n",
       "      <td>0.131238</td>\n",
       "      <td>0.065733</td>\n",
       "      <td>0.054242</td>\n",
       "      <td>0.134815</td>\n",
       "      <td>0.138610</td>\n",
       "      <td>0.881531</td>\n",
       "      <td>0.881432</td>\n",
       "      <td>0.157875</td>\n",
       "      <td>0.029477</td>\n",
       "      <td>0.076101</td>\n",
       "      <td>0.110876</td>\n",
       "      <td>NeuralLogicRec_V2_nov08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.178189</td>\n",
       "      <td>0.223044</td>\n",
       "      <td>0.125028</td>\n",
       "      <td>0.102923</td>\n",
       "      <td>0.119087</td>\n",
       "      <td>0.127079</td>\n",
       "      <td>0.749079</td>\n",
       "      <td>0.767438</td>\n",
       "      <td>0.150492</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.053174</td>\n",
       "      <td>0.087853</td>\n",
       "      <td>NeuralLogicRec_V2_no_special_constr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.173383</td>\n",
       "      <td>0.218115</td>\n",
       "      <td>0.122278</td>\n",
       "      <td>0.103332</td>\n",
       "      <td>0.118959</td>\n",
       "      <td>0.127215</td>\n",
       "      <td>0.754048</td>\n",
       "      <td>0.770119</td>\n",
       "      <td>0.151032</td>\n",
       "      <td>0.018206</td>\n",
       "      <td>0.053463</td>\n",
       "      <td>0.087564</td>\n",
       "      <td>NeuralLogicRec_V2_div05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.226741</td>\n",
       "      <td>0.127646</td>\n",
       "      <td>0.103955</td>\n",
       "      <td>0.119516</td>\n",
       "      <td>0.128760</td>\n",
       "      <td>0.745652</td>\n",
       "      <td>0.767512</td>\n",
       "      <td>0.150578</td>\n",
       "      <td>0.018206</td>\n",
       "      <td>0.056160</td>\n",
       "      <td>0.091513</td>\n",
       "      <td>NeuralLogicRec_V2_div05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.175724</td>\n",
       "      <td>0.226124</td>\n",
       "      <td>0.125047</td>\n",
       "      <td>0.101004</td>\n",
       "      <td>0.124607</td>\n",
       "      <td>0.131712</td>\n",
       "      <td>0.766314</td>\n",
       "      <td>0.782597</td>\n",
       "      <td>0.152175</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.094403</td>\n",
       "      <td>NeuralLogicRec_V2_div20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.146272</td>\n",
       "      <td>0.169439</td>\n",
       "      <td>0.095742</td>\n",
       "      <td>0.079727</td>\n",
       "      <td>0.126242</td>\n",
       "      <td>0.132683</td>\n",
       "      <td>0.801403</td>\n",
       "      <td>0.811495</td>\n",
       "      <td>0.153129</td>\n",
       "      <td>0.026972</td>\n",
       "      <td>0.073596</td>\n",
       "      <td>0.118197</td>\n",
       "      <td>NeuralLogicRec_V2_div20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.136291</td>\n",
       "      <td>0.149107</td>\n",
       "      <td>0.087509</td>\n",
       "      <td>0.075694</td>\n",
       "      <td>0.130650</td>\n",
       "      <td>0.135752</td>\n",
       "      <td>0.817705</td>\n",
       "      <td>0.825159</td>\n",
       "      <td>0.155824</td>\n",
       "      <td>0.029284</td>\n",
       "      <td>0.082651</td>\n",
       "      <td>0.127059</td>\n",
       "      <td>NeuralLogicRec_V2_div20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.145410</td>\n",
       "      <td>0.173752</td>\n",
       "      <td>0.095847</td>\n",
       "      <td>0.080034</td>\n",
       "      <td>0.131019</td>\n",
       "      <td>0.136193</td>\n",
       "      <td>0.798793</td>\n",
       "      <td>0.809165</td>\n",
       "      <td>0.155645</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>0.076293</td>\n",
       "      <td>0.118582</td>\n",
       "      <td>NeuralLogicRec_V2_div20_shuffle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.167837</td>\n",
       "      <td>0.220579</td>\n",
       "      <td>0.116843</td>\n",
       "      <td>0.095575</td>\n",
       "      <td>0.119593</td>\n",
       "      <td>0.128183</td>\n",
       "      <td>0.749532</td>\n",
       "      <td>0.769041</td>\n",
       "      <td>0.150981</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>0.085926</td>\n",
       "      <td>NeuralLogicRec_V2_div10_shuffle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.175601</td>\n",
       "      <td>0.215034</td>\n",
       "      <td>0.122077</td>\n",
       "      <td>0.099446</td>\n",
       "      <td>0.124167</td>\n",
       "      <td>0.131680</td>\n",
       "      <td>0.761142</td>\n",
       "      <td>0.777779</td>\n",
       "      <td>0.152082</td>\n",
       "      <td>0.019844</td>\n",
       "      <td>0.056546</td>\n",
       "      <td>0.091706</td>\n",
       "      <td>NeuralLogicRec_V2_div20_shuffle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.167468</td>\n",
       "      <td>0.214418</td>\n",
       "      <td>0.118565</td>\n",
       "      <td>0.098034</td>\n",
       "      <td>0.122272</td>\n",
       "      <td>0.129916</td>\n",
       "      <td>0.769281</td>\n",
       "      <td>0.781640</td>\n",
       "      <td>0.151398</td>\n",
       "      <td>0.017725</td>\n",
       "      <td>0.052307</td>\n",
       "      <td>0.084289</td>\n",
       "      <td>NeuralLogicRec_V2_div10_shuffle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.175478</td>\n",
       "      <td>0.219963</td>\n",
       "      <td>0.122161</td>\n",
       "      <td>0.099904</td>\n",
       "      <td>0.123465</td>\n",
       "      <td>0.131603</td>\n",
       "      <td>0.760041</td>\n",
       "      <td>0.779422</td>\n",
       "      <td>0.151427</td>\n",
       "      <td>0.022156</td>\n",
       "      <td>0.061844</td>\n",
       "      <td>0.100665</td>\n",
       "      <td>NeuralLogicRec_V2_div20_shuffle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.113370</td>\n",
       "      <td>0.143561</td>\n",
       "      <td>0.074932</td>\n",
       "      <td>0.059691</td>\n",
       "      <td>0.109615</td>\n",
       "      <td>0.119952</td>\n",
       "      <td>0.653072</td>\n",
       "      <td>0.670894</td>\n",
       "      <td>0.152888</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>NeuralLogicRec_AE_div20sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.158226</td>\n",
       "      <td>0.200246</td>\n",
       "      <td>0.107096</td>\n",
       "      <td>0.089773</td>\n",
       "      <td>0.125481</td>\n",
       "      <td>0.131872</td>\n",
       "      <td>0.778381</td>\n",
       "      <td>0.790931</td>\n",
       "      <td>0.153504</td>\n",
       "      <td>0.025046</td>\n",
       "      <td>0.069839</td>\n",
       "      <td>0.108275</td>\n",
       "      <td>NeuralLogicRec_V2_div30_sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.173259</td>\n",
       "      <td>0.228589</td>\n",
       "      <td>0.122382</td>\n",
       "      <td>0.101153</td>\n",
       "      <td>0.118679</td>\n",
       "      <td>0.127561</td>\n",
       "      <td>0.740288</td>\n",
       "      <td>0.759089</td>\n",
       "      <td>0.151144</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>0.047009</td>\n",
       "      <td>0.080339</td>\n",
       "      <td>NeuralLogicRec_V2_ICF02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.167468</td>\n",
       "      <td>0.213185</td>\n",
       "      <td>0.116039</td>\n",
       "      <td>0.097241</td>\n",
       "      <td>0.126037</td>\n",
       "      <td>0.132835</td>\n",
       "      <td>0.776268</td>\n",
       "      <td>0.789711</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.023312</td>\n",
       "      <td>0.070321</td>\n",
       "      <td>0.111165</td>\n",
       "      <td>NeuralLogicRec_V2_ICF05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.118669</td>\n",
       "      <td>0.128774</td>\n",
       "      <td>0.076669</td>\n",
       "      <td>0.066037</td>\n",
       "      <td>0.134630</td>\n",
       "      <td>0.139351</td>\n",
       "      <td>0.868811</td>\n",
       "      <td>0.869502</td>\n",
       "      <td>0.156906</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.099316</td>\n",
       "      <td>0.148155</td>\n",
       "      <td>NeuralLogicRec_V2_ICF10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.162046</td>\n",
       "      <td>0.223660</td>\n",
       "      <td>0.114419</td>\n",
       "      <td>0.092323</td>\n",
       "      <td>0.115711</td>\n",
       "      <td>0.124390</td>\n",
       "      <td>0.746738</td>\n",
       "      <td>0.763043</td>\n",
       "      <td>0.150089</td>\n",
       "      <td>0.014546</td>\n",
       "      <td>0.040266</td>\n",
       "      <td>0.066179</td>\n",
       "      <td>NeuralLogicRec_V2_ICF001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.174861</td>\n",
       "      <td>0.226124</td>\n",
       "      <td>0.122490</td>\n",
       "      <td>0.102776</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.129795</td>\n",
       "      <td>0.762063</td>\n",
       "      <td>0.780192</td>\n",
       "      <td>0.150738</td>\n",
       "      <td>0.018688</td>\n",
       "      <td>0.058280</td>\n",
       "      <td>0.094018</td>\n",
       "      <td>NeuralLogicRec_V2_ICF001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.096365</td>\n",
       "      <td>0.105977</td>\n",
       "      <td>0.058081</td>\n",
       "      <td>0.049236</td>\n",
       "      <td>0.136064</td>\n",
       "      <td>0.140210</td>\n",
       "      <td>0.898581</td>\n",
       "      <td>0.898499</td>\n",
       "      <td>0.157450</td>\n",
       "      <td>0.038532</td>\n",
       "      <td>0.099509</td>\n",
       "      <td>0.142087</td>\n",
       "      <td>NeuralLogicRec_V2_N10D15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.170055</td>\n",
       "      <td>0.202095</td>\n",
       "      <td>0.115350</td>\n",
       "      <td>0.093278</td>\n",
       "      <td>0.122339</td>\n",
       "      <td>0.129591</td>\n",
       "      <td>0.786139</td>\n",
       "      <td>0.799741</td>\n",
       "      <td>0.151124</td>\n",
       "      <td>0.022734</td>\n",
       "      <td>0.067431</td>\n",
       "      <td>0.105481</td>\n",
       "      <td>NeuralLogicRec_V2_N025_D025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.139002</td>\n",
       "      <td>0.171288</td>\n",
       "      <td>0.094025</td>\n",
       "      <td>0.078217</td>\n",
       "      <td>0.134229</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.850551</td>\n",
       "      <td>0.853568</td>\n",
       "      <td>0.155907</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.075908</td>\n",
       "      <td>0.114247</td>\n",
       "      <td>NeuralLogicRec_V2_N05_D05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.170548</td>\n",
       "      <td>0.222428</td>\n",
       "      <td>0.119416</td>\n",
       "      <td>0.098323</td>\n",
       "      <td>0.125969</td>\n",
       "      <td>0.132435</td>\n",
       "      <td>0.787782</td>\n",
       "      <td>0.800751</td>\n",
       "      <td>0.152228</td>\n",
       "      <td>0.024660</td>\n",
       "      <td>0.068202</td>\n",
       "      <td>0.104422</td>\n",
       "      <td>NeuralLogicRec_V2_N025_D05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.172150</td>\n",
       "      <td>0.216266</td>\n",
       "      <td>0.120417</td>\n",
       "      <td>0.100627</td>\n",
       "      <td>0.126179</td>\n",
       "      <td>0.132574</td>\n",
       "      <td>0.792619</td>\n",
       "      <td>0.803804</td>\n",
       "      <td>0.152025</td>\n",
       "      <td>0.026105</td>\n",
       "      <td>0.067624</td>\n",
       "      <td>0.105770</td>\n",
       "      <td>NeuralLogicRec_V2_N025_D05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.119532</td>\n",
       "      <td>0.159581</td>\n",
       "      <td>0.081692</td>\n",
       "      <td>0.064659</td>\n",
       "      <td>0.108085</td>\n",
       "      <td>0.121976</td>\n",
       "      <td>0.595023</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.155178</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>ConstraintAutoRec_N075_D075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.141836</td>\n",
       "      <td>0.173752</td>\n",
       "      <td>0.096263</td>\n",
       "      <td>0.079867</td>\n",
       "      <td>0.110573</td>\n",
       "      <td>0.122114</td>\n",
       "      <td>0.609290</td>\n",
       "      <td>0.633813</td>\n",
       "      <td>0.153308</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.009633</td>\n",
       "      <td>ConstraintAutoRec_N075_D075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.172150</td>\n",
       "      <td>0.214418</td>\n",
       "      <td>0.119536</td>\n",
       "      <td>0.099480</td>\n",
       "      <td>0.123189</td>\n",
       "      <td>0.130741</td>\n",
       "      <td>0.784285</td>\n",
       "      <td>0.795736</td>\n",
       "      <td>0.152405</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>0.060977</td>\n",
       "      <td>0.095752</td>\n",
       "      <td>NeuralLogicRec_V2_N025_alt_D05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.150709</td>\n",
       "      <td>0.195317</td>\n",
       "      <td>0.103082</td>\n",
       "      <td>0.085142</td>\n",
       "      <td>0.127893</td>\n",
       "      <td>0.133770</td>\n",
       "      <td>0.818153</td>\n",
       "      <td>0.825047</td>\n",
       "      <td>0.153753</td>\n",
       "      <td>0.025046</td>\n",
       "      <td>0.069839</td>\n",
       "      <td>0.109720</td>\n",
       "      <td>NeuralLogicRec_V2_N025_alt_D12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.162292</td>\n",
       "      <td>0.216266</td>\n",
       "      <td>0.112790</td>\n",
       "      <td>0.094072</td>\n",
       "      <td>0.127323</td>\n",
       "      <td>0.133498</td>\n",
       "      <td>0.795296</td>\n",
       "      <td>0.805951</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.024660</td>\n",
       "      <td>0.070417</td>\n",
       "      <td>0.106637</td>\n",
       "      <td>NeuralLogicRec_V2_N025_alt_D12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.163894</td>\n",
       "      <td>0.218731</td>\n",
       "      <td>0.114468</td>\n",
       "      <td>0.092683</td>\n",
       "      <td>0.117632</td>\n",
       "      <td>0.125940</td>\n",
       "      <td>0.762035</td>\n",
       "      <td>0.777313</td>\n",
       "      <td>0.150601</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.068202</td>\n",
       "      <td>NeuralLogicRec_V2_N025_D075_target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.169070</td>\n",
       "      <td>0.219347</td>\n",
       "      <td>0.119216</td>\n",
       "      <td>0.099406</td>\n",
       "      <td>0.125719</td>\n",
       "      <td>0.133190</td>\n",
       "      <td>0.788037</td>\n",
       "      <td>0.800617</td>\n",
       "      <td>0.152862</td>\n",
       "      <td>0.023312</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>0.105866</td>\n",
       "      <td>NeuralLogicRec_V2_N025_D075_out</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    precision@5     map@1     map@5    map@10  diversity@5  diversity@10  \\\n",
       "0      0.118299  0.138016  0.076476  0.063892     0.137715      0.140510   \n",
       "1      0.019470  0.018484  0.010192  0.007359     0.177103      0.181647   \n",
       "2      0.022921  0.028343  0.012471  0.009858     0.154523      0.161315   \n",
       "3      0.154036  0.189772  0.105494  0.083369     0.113045      0.128833   \n",
       "4      0.154405  0.184227  0.105062  0.085711     0.112687      0.126375   \n",
       "5      0.153913  0.182378  0.103851  0.084182     0.114962      0.125772   \n",
       "6      0.158842  0.203943  0.110223  0.087918     0.117859      0.127593   \n",
       "7      0.150339  0.175601  0.100489  0.081072     0.118068      0.129446   \n",
       "8      0.165003  0.199014  0.110928  0.089545     0.115360      0.124318   \n",
       "9      0.169070  0.205176  0.115598  0.092897     0.114370      0.123962   \n",
       "10     0.164633  0.195933  0.112756  0.091934     0.115658      0.124343   \n",
       "11     0.169070  0.207640  0.114828  0.092392     0.111643      0.122752   \n",
       "12     0.078743  0.077018  0.044914  0.040270     0.138219      0.141831   \n",
       "13     0.171041  0.218731  0.121545  0.098995     0.121382      0.129155   \n",
       "14     0.160690  0.198398  0.109538  0.090368     0.125102      0.132677   \n",
       "15     0.173383  0.223044  0.121525  0.101693     0.123560      0.131110   \n",
       "16     0.117190  0.142945  0.077055  0.062324     0.118228      0.125124   \n",
       "17     0.168207  0.223660  0.119350  0.097883     0.120342      0.128665   \n",
       "18     0.174985  0.202095  0.119716  0.099546     0.120600      0.128802   \n",
       "19     0.162046  0.202711  0.111448  0.090889     0.121806      0.130240   \n",
       "20     0.154775  0.192853  0.106720  0.087813     0.127122      0.134270   \n",
       "21     0.170548  0.204559  0.116194  0.095004     0.122166      0.130144   \n",
       "22     0.149476  0.197166  0.103886  0.084971     0.126812      0.132980   \n",
       "23     0.105360  0.131238  0.065733  0.054242     0.134815      0.138610   \n",
       "24     0.178189  0.223044  0.125028  0.102923     0.119087      0.127079   \n",
       "25     0.173383  0.218115  0.122278  0.103332     0.118959      0.127215   \n",
       "26     0.180900  0.226741  0.127646  0.103955     0.119516      0.128760   \n",
       "27     0.175724  0.226124  0.125047  0.101004     0.124607      0.131712   \n",
       "28     0.146272  0.169439  0.095742  0.079727     0.126242      0.132683   \n",
       "29     0.136291  0.149107  0.087509  0.075694     0.130650      0.135752   \n",
       "30     0.145410  0.173752  0.095847  0.080034     0.131019      0.136193   \n",
       "31     0.167837  0.220579  0.116843  0.095575     0.119593      0.128183   \n",
       "32     0.175601  0.215034  0.122077  0.099446     0.124167      0.131680   \n",
       "33     0.167468  0.214418  0.118565  0.098034     0.122272      0.129916   \n",
       "34     0.175478  0.219963  0.122161  0.099904     0.123465      0.131603   \n",
       "35     0.113370  0.143561  0.074932  0.059691     0.109615      0.119952   \n",
       "36     0.158226  0.200246  0.107096  0.089773     0.125481      0.131872   \n",
       "37     0.173259  0.228589  0.122382  0.101153     0.118679      0.127561   \n",
       "38     0.167468  0.213185  0.116039  0.097241     0.126037      0.132835   \n",
       "39     0.118669  0.128774  0.076669  0.066037     0.134630      0.139351   \n",
       "40     0.162046  0.223660  0.114419  0.092323     0.115711      0.124390   \n",
       "41     0.174861  0.226124  0.122490  0.102776     0.121800      0.129795   \n",
       "42     0.096365  0.105977  0.058081  0.049236     0.136064      0.140210   \n",
       "43     0.170055  0.202095  0.115350  0.093278     0.122339      0.129591   \n",
       "44     0.139002  0.171288  0.094025  0.078217     0.134229      0.138900   \n",
       "45     0.170548  0.222428  0.119416  0.098323     0.125969      0.132435   \n",
       "46     0.172150  0.216266  0.120417  0.100627     0.126179      0.132574   \n",
       "47     0.119532  0.159581  0.081692  0.064659     0.108085      0.121976   \n",
       "48     0.141836  0.173752  0.096263  0.079867     0.110573      0.122114   \n",
       "49     0.172150  0.214418  0.119536  0.099480     0.123189      0.130741   \n",
       "50     0.150709  0.195317  0.103082  0.085142     0.127893      0.133770   \n",
       "51     0.162292  0.216266  0.112790  0.094072     0.127323      0.133498   \n",
       "52     0.163894  0.218731  0.114468  0.092683     0.117632      0.125940   \n",
       "53     0.169070  0.219347  0.119216  0.099406     0.125719      0.133190   \n",
       "\n",
       "       epc@5    epc@10     epd@5  coverage@1  coverage@5  coverage@10  \\\n",
       "0   0.839210  0.841383  0.159020    0.017436    0.048261     0.074367   \n",
       "1   0.947601  0.943642  0.171897    0.003757    0.012716     0.022156   \n",
       "2   0.941178  0.942126  0.167028    0.008670    0.028417     0.050284   \n",
       "3   0.633749  0.661420  0.151949    0.003468    0.010789     0.018592   \n",
       "4   0.639377  0.669451  0.150891    0.004142    0.011271     0.020229   \n",
       "5   0.668409  0.694873  0.150068    0.005876    0.016954     0.029959   \n",
       "6   0.661247  0.687662  0.151883    0.004624    0.013679     0.024082   \n",
       "7   0.639319  0.668453  0.153940    0.004239    0.011078     0.022060   \n",
       "8   0.740063  0.760826  0.150171    0.013294    0.043637     0.067527   \n",
       "9   0.714903  0.736431  0.150075    0.011945    0.039881     0.066853   \n",
       "10  0.743881  0.760968  0.150097    0.015991    0.045949     0.072825   \n",
       "11  0.729649  0.749089  0.149486    0.012908    0.039592     0.064541   \n",
       "12  0.898378  0.897465  0.160432    0.043830    0.120701     0.173008   \n",
       "13  0.748632  0.770310  0.149960    0.018206    0.055101     0.092091   \n",
       "14  0.771944  0.790142  0.151507    0.027647    0.089972     0.144302   \n",
       "15  0.753833  0.772850  0.152130    0.020518    0.058376     0.095848   \n",
       "16  0.627615  0.645038  0.155018    0.002890    0.008092     0.011656   \n",
       "17  0.752063  0.770449  0.151292    0.016858    0.052018     0.087660   \n",
       "18  0.751926  0.768161  0.151063    0.017821    0.048358     0.078220   \n",
       "19  0.758690  0.777696  0.151526    0.022445    0.073500     0.120123   \n",
       "20  0.769263  0.788079  0.152851    0.027550    0.089201     0.146518   \n",
       "21  0.781983  0.795550  0.152038    0.020711    0.057413     0.090261   \n",
       "22  0.830198  0.834548  0.154223    0.025913    0.063963     0.098545   \n",
       "23  0.881531  0.881432  0.157875    0.029477    0.076101     0.110876   \n",
       "24  0.749079  0.767438  0.150492    0.019170    0.053174     0.087853   \n",
       "25  0.754048  0.770119  0.151032    0.018206    0.053463     0.087564   \n",
       "26  0.745652  0.767512  0.150578    0.018206    0.056160     0.091513   \n",
       "27  0.766314  0.782597  0.152175    0.020422    0.056738     0.094403   \n",
       "28  0.801403  0.811495  0.153129    0.026972    0.073596     0.118197   \n",
       "29  0.817705  0.825159  0.155824    0.029284    0.082651     0.127059   \n",
       "30  0.798793  0.809165  0.155645    0.028128    0.076293     0.118582   \n",
       "31  0.749532  0.769041  0.150981    0.016858    0.052211     0.085926   \n",
       "32  0.761142  0.777779  0.152082    0.019844    0.056546     0.091706   \n",
       "33  0.769281  0.781640  0.151398    0.017725    0.052307     0.084289   \n",
       "34  0.760041  0.779422  0.151427    0.022156    0.061844     0.100665   \n",
       "35  0.653072  0.670894  0.152888    0.004528    0.012138     0.019170   \n",
       "36  0.778381  0.790931  0.153504    0.025046    0.069839     0.108275   \n",
       "37  0.740288  0.759089  0.151144    0.015991    0.047009     0.080339   \n",
       "38  0.776268  0.789711  0.152697    0.023312    0.070321     0.111165   \n",
       "39  0.868811  0.869502  0.156906    0.037087    0.099316     0.148155   \n",
       "40  0.746738  0.763043  0.150089    0.014546    0.040266     0.066179   \n",
       "41  0.762063  0.780192  0.150738    0.018688    0.058280     0.094018   \n",
       "42  0.898581  0.898499  0.157450    0.038532    0.099509     0.142087   \n",
       "43  0.786139  0.799741  0.151124    0.022734    0.067431     0.105481   \n",
       "44  0.850551  0.853568  0.155907    0.030826    0.075908     0.114247   \n",
       "45  0.787782  0.800751  0.152228    0.024660    0.068202     0.104422   \n",
       "46  0.792619  0.803804  0.152025    0.026105    0.067624     0.105770   \n",
       "47  0.595023  0.614923  0.155178    0.001541    0.003468     0.005587   \n",
       "48  0.609290  0.633813  0.153308    0.002312    0.005491     0.009633   \n",
       "49  0.784285  0.795736  0.152405    0.020807    0.060977     0.095752   \n",
       "50  0.818153  0.825047  0.153753    0.025046    0.069839     0.109720   \n",
       "51  0.795296  0.805951  0.153100    0.024660    0.070417     0.106637   \n",
       "52  0.762035  0.777313  0.150601    0.017243    0.043734     0.068202   \n",
       "53  0.788037  0.800617  0.152862    0.023312    0.068491     0.105866   \n",
       "\n",
       "                                   name  \n",
       "0                NeuralLogicRec_default  \n",
       "1                NeuralLogicRec_default  \n",
       "2                NeuralLogicRec_default  \n",
       "3                NeuralLogicRec_default  \n",
       "4                NeuralLogicRec_default  \n",
       "5                NeuralLogicRec_default  \n",
       "6                NeuralLogicRec_default  \n",
       "7                NeuralLogicRec_default  \n",
       "8                NeuralLogicRec_default  \n",
       "9                NeuralLogicRec_default  \n",
       "10               NeuralLogicRec_default  \n",
       "11               NeuralLogicRec_default  \n",
       "12               NeuralLogicRec_default  \n",
       "13               NeuralLogicRec_default  \n",
       "14               NeuralLogicRec_default  \n",
       "15               NeuralLogicRec_default  \n",
       "16               NeuralLogicRec_default  \n",
       "17               NeuralLogicRec_default  \n",
       "18                    NeuralLogicRec_V2  \n",
       "19                    NeuralLogicRec_V2  \n",
       "20                    NeuralLogicRec_V2  \n",
       "21                    NeuralLogicRec_V2  \n",
       "22              NeuralLogicRec_V2_nov08  \n",
       "23              NeuralLogicRec_V2_nov08  \n",
       "24  NeuralLogicRec_V2_no_special_constr  \n",
       "25              NeuralLogicRec_V2_div05  \n",
       "26              NeuralLogicRec_V2_div05  \n",
       "27              NeuralLogicRec_V2_div20  \n",
       "28              NeuralLogicRec_V2_div20  \n",
       "29              NeuralLogicRec_V2_div20  \n",
       "30      NeuralLogicRec_V2_div20_shuffle  \n",
       "31      NeuralLogicRec_V2_div10_shuffle  \n",
       "32      NeuralLogicRec_V2_div20_shuffle  \n",
       "33      NeuralLogicRec_V2_div10_shuffle  \n",
       "34      NeuralLogicRec_V2_div20_shuffle  \n",
       "35            NeuralLogicRec_AE_div20sh  \n",
       "36           NeuralLogicRec_V2_div30_sh  \n",
       "37              NeuralLogicRec_V2_ICF02  \n",
       "38              NeuralLogicRec_V2_ICF05  \n",
       "39              NeuralLogicRec_V2_ICF10  \n",
       "40             NeuralLogicRec_V2_ICF001  \n",
       "41             NeuralLogicRec_V2_ICF001  \n",
       "42             NeuralLogicRec_V2_N10D15  \n",
       "43          NeuralLogicRec_V2_N025_D025  \n",
       "44            NeuralLogicRec_V2_N05_D05  \n",
       "45           NeuralLogicRec_V2_N025_D05  \n",
       "46           NeuralLogicRec_V2_N025_D05  \n",
       "47          ConstraintAutoRec_N075_D075  \n",
       "48          ConstraintAutoRec_N075_D075  \n",
       "49       NeuralLogicRec_V2_N025_alt_D05  \n",
       "50       NeuralLogicRec_V2_N025_alt_D12  \n",
       "51       NeuralLogicRec_V2_N025_alt_D12  \n",
       "52   NeuralLogicRec_V2_N025_D075_target  \n",
       "53      NeuralLogicRec_V2_N025_D075_out  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ae_evals)[['precision@5', 'map@1', 'map@5', 'map@10', 'diversity@5', 'diversity@10', 'epc@5', 'epc@10', 'epd@5', 'coverage@1', 'coverage@5', 'coverage@10', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_data = pd.DataFrame(ae_evals[-8:])\n",
    "eval_data = eval_data.sort_values(by='epochs_trained')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(eval_data['epochs_trained'], eval_data['diversity@5'])\n",
    "plt.plot(eval_data['epochs_trained'], eval_data['map@5'])\n",
    "plt.plot(eval_data['epochs_trained'], eval_data['map@1'])\n",
    "plt.show()\n",
    "plt.bar(eval_data.index, eval_data['map@1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.convert_to_tensor(np.arange(100).reshape(5,20), dtype=tf.float32)\n",
    "a = tf.transpose(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([13  8  2 12  7  6 17 15 15  2], shape=(10,), dtype=int32)\n",
      "tf.Tensor([ 2 16 11  6  8 17  6  7  4 19], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "item_sample_a = tf.random.uniform([10], minval=0, maxval=20, dtype=tf.int32)\n",
    "item_sample_b = tf.random.uniform([10], minval=0, maxval=20, dtype=tf.int32)\n",
    "print(item_sample_a)\n",
    "print(item_sample_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.nn.embedding_lookup(a, item_sample_a)\n",
    "y = tf.nn.embedding_lookup(a, item_sample_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=97, shape=(10,), dtype=float32, numpy=\n",
       "array([0.9947558 , 0.9979024 , 0.9962775 , 0.99858963, 0.9999572 ,\n",
       "       0.9958922 , 0.9958922 , 0.9977732 , 0.9953644 , 0.9894124 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.losses.cosine_similarity(x, y,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
