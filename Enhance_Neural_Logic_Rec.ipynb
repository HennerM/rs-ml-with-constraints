{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Processing batch done\n",
      "Process batch\n",
      "Process batch\n",
      "Processing batch done\n",
      "Processing batch done\n",
      "Process batch\n",
      "Process batch\n",
      "Processing batch done\n",
      "Processing batch done\n",
      "Process batch\n",
      "Process batch\n",
      "Processing batch done\n",
      "Processing batch done\n"
     ]
    }
   ],
   "source": [
    "ev = evaluation.Evaluation(ml_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.common\n",
    "import evaluation\n",
    "import importlib\n",
    "import numpy as np\n",
    "import time\n",
    "from models.ConstraintAutoRec import ConstraintAutoRec \n",
    "import models.NeuralLogicRec\n",
    "import tensorflow as tf\n",
    "importlib.reload(utils.common)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(models.NeuralLogicRec)\n",
    "import itertools\n",
    "\n",
    "ml_small = utils.common.ml_small\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlr = models.NeuralLogicRec.NLR(ml_small['user'], ml_small['dimensions'], epochs=1, embedding_dim=16, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 Loss at step 30: 0.1612, time: 4.126\n",
      "Epoch #1 Loss at step 30: 0.1529, time: 3.426\n",
      "Epoch #2 Loss at step 30: 0.1396, time: 3.326\n",
      "Epoch #3 Loss at step 30: 0.1290, time: 3.341\n",
      "Epoch #4 Loss at step 30: 0.1193, time: 3.333\n",
      "Batch nr 1 predicted\n",
      "Batch nr 2 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.43669181034482757, 'precision': 0.7975158542534428, 'recall': 0.4115342196859317, 'map@1': 0.5, 'map@5': 0.16666666666666666, 'map@10': 0.08338758680555555, 'diversity@5': 0.3440100524942826, 'diversity@10': 0.3515551350557251, 'epc@5': 0.9016734403773413, 'epc@10': 0.9219850066296027, 'epd@5': 0.3606010562486245, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 5, 'batch_size': 20}\n",
      "Epoch #0 Loss at step 30: 0.1177, time: 3.318\n",
      "Epoch #1 Loss at step 30: 0.1083, time: 3.360\n",
      "Epoch #2 Loss at step 30: 0.1105, time: 3.299\n",
      "Epoch #3 Loss at step 30: 0.1029, time: 3.268\n",
      "Epoch #4 Loss at step 30: 0.1006, time: 3.266\n",
      "Batch nr 1 predicted\n",
      "Batch nr 2 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.4398777173913043, 'precision': 0.808988976140139, 'recall': 0.4035610935729318, 'map@1': 0.0, 'map@5': 0.06515625, 'map@10': 0.10688368055555555, 'diversity@5': 0.30844043960505907, 'diversity@10': 0.3295618440441693, 'epc@5': 0.8631240293797189, 'epc@10': 0.8501299880926978, 'epd@5': 0.3479054261211456, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 5, 'batch_size': 20}\n",
      "Epoch #0 Loss at step 30: 0.1004, time: 3.533\n",
      "Epoch #1 Loss at step 30: 0.0953, time: 3.477\n",
      "Epoch #2 Loss at step 30: 0.0943, time: 3.563\n",
      "Epoch #3 Loss at step 30: 0.0972, time: 3.508\n",
      "Epoch #4 Loss at step 30: 0.0924, time: 3.316\n",
      "Batch nr 1 predicted\n",
      "Batch nr 2 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.4298456240629685, 'precision': 0.7945203081232493, 'recall': 0.40598186822081916, 'map@1': 0.5, 'map@5': 0.2751953125, 'map@10': 0.15985894097222222, 'diversity@5': 0.3013635272383315, 'diversity@10': 0.3159149384588172, 'epc@5': 0.8188941676917222, 'epc@10': 0.829824160763039, 'epd@5': 0.34780443431437524, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 5, 'batch_size': 20}\n"
     ]
    }
   ],
   "source": [
    "nlr.epochs = 5\n",
    "for i in range(3):\n",
    "    nlr.train(utils.common.load_dataset(ml_small), ml_small['train']['records'])\n",
    "    print(ev.evaluate(nlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 15:18:16.759938 140578652948288 deprecation.py:323] From /home/markush/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1256: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 Loss at step 30: 0.1587, time: 10.427\n",
      "Epoch #1 Loss at step 30: 0.1250, time: 8.908\n",
      "Epoch #2 Loss at step 30: 0.0996, time: 8.984\n",
      "Epoch #3 Loss at step 30: 0.0909, time: 9.054\n",
      "Epoch #4 Loss at step 30: 0.0840, time: 8.819\n",
      "Batch nr 1 predicted\n",
      "Batch nr 2 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.43637556221889057, 'precision': 0.7923198233717079, 'recall': 0.42652430386919216, 'map@1': 0.5, 'map@5': 0.2007421875, 'map@10': 0.10066406250000001, 'diversity@5': 0.3453931110091504, 'diversity@10': 0.3512463610830536, 'epc@5': 0.9262681588170882, 'epc@10': 0.9108492862577728, 'epd@5': 0.3602412945398409, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 5, 'batch_size': 20}\n",
      "Epoch #0 Loss at step 30: 0.1042, time: 8.931\n",
      "Epoch #1 Loss at step 30: 0.0998, time: 8.757\n",
      "Epoch #2 Loss at step 30: 0.0985, time: 8.782\n",
      "Epoch #3 Loss at step 30: 0.0950, time: 8.883\n",
      "Epoch #4 Loss at step 30: 0.0952, time: 9.273\n",
      "Batch nr 1 predicted\n",
      "Batch nr 2 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.44028181221889057, 'precision': 0.7903030303030303, 'recall': 0.4382386271652906, 'map@1': 0.50390625, 'map@5': 0.40078125000000003, 'map@10': 0.23169642857142858, 'diversity@5': 0.3418598488427645, 'diversity@10': 0.34077344410673155, 'epc@5': 0.8230641421825744, 'epc@10': 0.846065890564839, 'epd@5': 0.36347136129897895, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 5, 'batch_size': 20}\n",
      "Epoch #0 Loss at step 30: 0.0986, time: 10.601\n",
      "Epoch #1 Loss at step 30: 0.0987, time: 9.366\n",
      "Epoch #2 Loss at step 30: 0.0946, time: 9.262\n",
      "Epoch #3 Loss at step 30: 0.0960, time: 9.300\n",
      "Epoch #4 Loss at step 30: 0.0949, time: 8.928\n",
      "Batch nr 1 predicted\n",
      "Batch nr 2 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating NeuralLogicRec |============================================================>| 100.0% \n",
      "{'accuracy': 0.477587378185907, 'precision': 0.7983009166107757, 'recall': 0.48279403432086776, 'map@1': 0.5, 'map@5': 0.27545572916666666, 'map@10': 0.19888237847222223, 'diversity@5': 0.3077652809538757, 'diversity@10': 0.3229271268650532, 'epc@5': 0.7882594131483099, 'epc@10': 0.8254656948104101, 'epd@5': 0.36984580718997034, 'name': 'NeuralLogicRec', 'latent_dim': 128, 'epochs': 5, 'batch_size': 20}\n"
     ]
    }
   ],
   "source": [
    "nlr.epochs = 5\n",
    "for i in range(3):\n",
    "    nlr.train(utils.common.load_dataset(ml_small), ml_small['train']['records'])\n",
    "    print(ev.evaluate(nlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0696392e-06 3.9041042e-06 5.6028366e-06 ... 9.8202431e-01\n",
      "  9.8493266e-01 9.8527825e-01]]\n"
     ]
    }
   ],
   "source": [
    "# print(np.flip(np.argsort(nlr.predict_single_user(3))))\n",
    "pred = nlr.model([4])\n",
    "# inf = models.NeuralLogicRec.map_inference(nlr.model, pred)\n",
    "print(np.sort(pred['likes']))\n",
    "# print(np.sort(inf['likes'].numpy()))\n",
    "# nlr.model(np.array(1), np.array(1))\n",
    "# ev.evaluate(nlr)\n",
    "# pred = nlr.model(tf.convert_to_tensor([1, 2, 3], dtype=tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = tf.convert_to_tensor([x for x in itertools.permutations(range(600), 2)])\n",
    "u1 = u[:,0]\n",
    "u2 = u[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True False False  True False False  True False False  True]\n",
      " [False False  True False False  True False False  True False]\n",
      " [False  True False False  True False False  True False False]], shape=(3, 10), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]], shape=(3, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "num_movies = 10\n",
    "num_user = 3\n",
    "rated = tf.convert_to_tensor(np.arange(num_movies * num_user).reshape([num_user, num_movies]) % 3 == 0)\n",
    "seen = tf.convert_to_tensor(np.arange(num_movies * num_user, num_movies * num_user * 2).reshape([num_user, num_movies]))\n",
    "users = tf.convert_to_tensor(np.arange(num_user))\n",
    "users = tf.convert_to_tensor([20, 10, 5, 0, 40])\n",
    "print(rated)\n",
    "print(seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[20 10]\n",
      " [20  5]\n",
      " [20  0]\n",
      " [20 40]\n",
      " [10 20]\n",
      " [10  5]\n",
      " [10  0]\n",
      " [10 40]\n",
      " [ 5 20]\n",
      " [ 5 10]\n",
      " [ 5  0]\n",
      " [ 5 40]\n",
      " [ 0 20]\n",
      " [ 0 10]\n",
      " [ 0  5]\n",
      " [ 0 40]\n",
      " [40 20]\n",
      " [40 10]\n",
      " [40  5]\n",
      " [40  0]], shape=(20, 2), dtype=int32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index 3 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-0c6b31a13617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_cross\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_cross\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrated_cross\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(rated_cross)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-0c6b31a13617>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_cross\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_cross\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrated_cross\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(rated_cross)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    844\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   9965\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9966\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9967\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9968\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9969\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbegin_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index 3 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "user_cross = tf.convert_to_tensor([x for x in itertools.permutations(users.numpy(), 2)])\n",
    "print(user_cross)\n",
    "rated_cross = tf.convert_to_tensor([tf.stack([rated[x[0]], rated[x[1]]], axis=0) for x in itertools.permutations(range(len(users.numpy())), 2)])\n",
    "# print(rated_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.47242978 -0.7581886   0.6176951  -0.5861519   0.3641987\n",
      "    0.10563103  0.61831975 -0.37575603]]\n",
      "\n",
      " [[ 0.47242978 -0.7581886   0.6176951  -0.5861519   0.3641987\n",
      "    0.10563103  0.61831975 -0.37575603]]\n",
      "\n",
      " [[ 0.47242978 -0.7581886   0.6176951  -0.5861519   0.3641987\n",
      "    0.10563103  0.61831975 -0.37575603]]\n",
      "\n",
      " [[ 0.47242978 -0.7581886   0.6176951  -0.5861519   0.3641987\n",
      "    0.10563103  0.61831975 -0.37575603]]\n",
      "\n",
      " [[ 0.32968965  1.3128943   0.4282597  -1.8893449  -1.0829191\n",
      "   -1.2234583   0.99611586  0.7264877 ]]\n",
      "\n",
      " [[ 0.32968965  1.3128943   0.4282597  -1.8893449  -1.0829191\n",
      "   -1.2234583   0.99611586  0.7264877 ]]\n",
      "\n",
      " [[ 0.32968965  1.3128943   0.4282597  -1.8893449  -1.0829191\n",
      "   -1.2234583   0.99611586  0.7264877 ]]\n",
      "\n",
      " [[ 0.32968965  1.3128943   0.4282597  -1.8893449  -1.0829191\n",
      "   -1.2234583   0.99611586  0.7264877 ]]\n",
      "\n",
      " [[ 0.6136244   1.5436143   2.036422    1.5196469   0.08901728\n",
      "   -0.90769035 -1.6418009  -0.3131709 ]]\n",
      "\n",
      " [[ 0.6136244   1.5436143   2.036422    1.5196469   0.08901728\n",
      "   -0.90769035 -1.6418009  -0.3131709 ]]\n",
      "\n",
      " [[ 0.6136244   1.5436143   2.036422    1.5196469   0.08901728\n",
      "   -0.90769035 -1.6418009  -0.3131709 ]]\n",
      "\n",
      " [[ 0.6136244   1.5436143   2.036422    1.5196469   0.08901728\n",
      "   -0.90769035 -1.6418009  -0.3131709 ]]\n",
      "\n",
      " [[-0.22931455  0.21385668 -0.18404375 -1.6126455  -1.4268681\n",
      "   -1.0110536  -1.2846677   0.08389689]]\n",
      "\n",
      " [[-0.22931455  0.21385668 -0.18404375 -1.6126455  -1.4268681\n",
      "   -1.0110536  -1.2846677   0.08389689]]\n",
      "\n",
      " [[-0.22931455  0.21385668 -0.18404375 -1.6126455  -1.4268681\n",
      "   -1.0110536  -1.2846677   0.08389689]]\n",
      "\n",
      " [[-0.22931455  0.21385668 -0.18404375 -1.6126455  -1.4268681\n",
      "   -1.0110536  -1.2846677   0.08389689]]\n",
      "\n",
      " [[-0.7453738  -1.3101593  -0.6682748   1.30258    -1.2745917\n",
      "    0.01897669  0.9483459   0.76908296]]\n",
      "\n",
      " [[-0.7453738  -1.3101593  -0.6682748   1.30258    -1.2745917\n",
      "    0.01897669  0.9483459   0.76908296]]\n",
      "\n",
      " [[-0.7453738  -1.3101593  -0.6682748   1.30258    -1.2745917\n",
      "    0.01897669  0.9483459   0.76908296]]\n",
      "\n",
      " [[-0.7453738  -1.3101593  -0.6682748   1.30258    -1.2745917\n",
      "    0.01897669  0.9483459   0.76908296]]], shape=(20, 1, 8), dtype=float32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 83048 values, but the requested shape has 240 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-89ba1f5cc17a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muser_embedd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_movies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mexpanded_embedd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_movies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mitem_embedd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_embedd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_cross\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   7695\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7696\u001b[0m         return reshape_eager_fallback(\n\u001b[0;32m-> 7697\u001b[0;31m             tensor, shape, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   7698\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7699\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   7745\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7746\u001b[0m   _result = _execute.execute(b\"Reshape\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 7747\u001b[0;31m                              ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m   7748\u001b[0m   _execute.record_gradient(\n\u001b[1;32m   7749\u001b[0m       \"Reshape\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 83048 values, but the requested shape has 240 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "user_emb = tf.expand_dims(tf.nn.embedding_lookup(nlr.model.user_embedding, user_cross), axis=2)\n",
    "print(user_emb[:, 0])\n",
    "user_embedd = tf.tile(user_emb, [1, 1, num_movies, 1])\n",
    "expanded_embedd = tf.reshape(nlr.model.item_embedding, [1, 1, num_movies, 24])\n",
    "item_embedd = tf.tile(expanded_embedd, [len(user_cross), 2, 1, 1])\n",
    "print(item_embed.shape)\n",
    "print(user_embedd.shape)\n",
    "inp = tf.concat([user_embedd, item_embedd], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-f88fa627ff7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikes_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'inp' is not defined"
     ]
    }
   ],
   "source": [
    "result = tf.squeeze(nlr.model.likes_estimator(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  2  11 101]\n",
      " [ 11  20 110]\n",
      " [101 110 200]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "num_movies = 5\n",
    "users = tf.convert_to_tensor([1, 10, 100])\n",
    "embed_user = tf.expand_dims(users, axis=1)\n",
    "users_1 = tf.tile(tf.expand_dims(embed_user, axis=1), [1, len(users), 1])\n",
    "users_2 = tf.tile(tf.expand_dims(embed_user, axis=0), [len(users),1, 1])\n",
    "# print(embed_user)\n",
    "# embed_user = tf.tile(embed_user, [1, num_movies, 1])\n",
    "# expanded_embedd = tf.expand_dims(nlr.model.item_embedding[0:num_movies], axis=0)\n",
    "# embed_item = tf.tile(expanded_embedd, [len(users), 1, 1])\n",
    "sim_input = tf.reduce_sum(tf.concat([users_1, users_2], axis=-1), axis=-1)\n",
    "print(sim_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_ratings = tf.tile(tf.expand_dims(rated, axis=0), [3, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.expand_dims(tf.convert_to_tensor(10), axis=0)\n",
    "b = tf.expand_dims(tf.convert_to_tensor(20), axis=0)\n",
    "c = tf.convert_to_tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=134207, shape=(6,), dtype=int32, numpy=array([10, 20,  1,  2,  3,  4], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([a,b, c], axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
