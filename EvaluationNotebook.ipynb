{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.BPR' from '/home/ec2-user/SageMaker/rs-ml-with-constraints/models/BPR.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.common\n",
    "import evaluation\n",
    "import importlib\n",
    "import numpy as np\n",
    "import time\n",
    "import models.MatrixFactorization\n",
    "import models.BPR\n",
    "import models.ConstraintAutoRec\n",
    "importlib.reload(utils.common)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(models.MatrixFactorization)\n",
    "importlib.reload(models.BPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/rs-ml-with-constraints/evaluation.py\", line 251, in work_on_batch\n",
      "    data = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/rs-ml-with-constraints/evaluation.py\", line 251, in work_on_batch\n",
      "    data = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "ev = evaluation.Evaluation(utils.common.movie_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2770/4327 [==================>...........] - ETA: 40s - loss: 0.1095 - accuracy: 0.0071"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-25ce353c298d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstraintAutoRec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstraintAutoRec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_lens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dimensions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnovelty_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_lens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/rs-ml-with-constraints/models/ConstraintAutoRec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, nr_records)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnr_records\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \"\"\"\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2104\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m         \u001b[0;34m\"IteratorGetNextSync\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m         \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.ConstraintAutoRec.ConstraintAutoRec(utils.common.movie_lens['dimensions'], epochs=10, novelty_weight=0.1, diversity_weight=0.1, latent_dim=64)\n",
    "model.train(utils.common.load_dataset(utils.common.movie_lens, 'train'), utils.common.movie_lens['train']['records'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch nr 1 predicted\n",
      "Batch nr 2 predicted\n",
      "Batch nr 3 predicted\n",
      "Batch nr 4 predicted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7615029021888029,\n",
       " 'precision': 0.8941274148439151,\n",
       " 'recall': 0.8101808587019432,\n",
       " 'map@1': 0.23828125,\n",
       " 'map@5': 0.1394394259982639,\n",
       " 'map@10': 0.11109135980238449,\n",
       " 'diversity@5': 0.22559207396193848,\n",
       " 'diversity@10': 0.24281211352016488,\n",
       " 'epc@5': 0.738564504069548,\n",
       " 'epc@10': 0.7556898195335914,\n",
       " 'epd@5': 0.3026981063782443,\n",
       " 'name': 'ConstraintAutoRec',\n",
       " 'dimensions': 10381,\n",
       " 'latent_dims': 64,\n",
       " 'accuracy_weight': 1.0,\n",
       " 'novelty_weight': 0.1,\n",
       " 'diversity_weight': 0.1,\n",
       " 'epochs': 10,\n",
       " 'batch_size': 32,\n",
       " 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.evaluate_single_thread(model, max_nr_batches = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "diversity_model = models.ConstraintAutoRec.ConstraintAutoRec(utils.common.movie_lens['dimensions'], epochs=30, novelty_weight=0.25, diversity_weight=2.0)\n",
    "diversity_model.train(utils.common.load_dataset(utils.common.movie_lens, 'train'), utils.common.movie_lens['train']['records'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(novelty_weight):\n",
    "    m = models.ConstraintAutoRec.ConstraintAutoRec(utils.common.movie_lens['dimensions'], epochs=15, novelty_weight=novelty_weight, diversity_weight=0, batch_size=128)\n",
    "    m.train(utils.common.load_dataset(utils.common.movie_lens, 'train'), utils.common.movie_lens['train']['records'])\n",
    "    return m\n",
    "\n",
    "nov_models2 = [create_model(x) for x in [0.1, 0.5, 1.0, 2.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#ev = evaluation.Evaluation(utils.common.movie_lens)\n",
    "#big_eval = ev.evaluate_models(models)\n",
    "big_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(eval_data.index, eval_data['epc@10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eval_data['novelty_weight'], eval_data['epc@10'], 'ro', ls='--')\n",
    "plt.plot(eval_data['novelty_weight'], eval_data['accuracy'], 'bo', ls='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(data, axis, x_param):\n",
    "    bottom = data[axis].min() \n",
    "    top = data[axis].max()\n",
    "    margin = (top - bottom) * 0.05\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(data.index, data[axis] )\n",
    "    ax.set_xticks(data.index)\n",
    "    ax.set_xticklabels(data[x_param])\n",
    "    ax.set_ylabel(axis)\n",
    "    ax.set_xlabel(x_param)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mf = models.MatrixFactorization.MatrixFactorization(utils.common.movie_lens['user'], utils.common.movie_lens['dimensions'], epochs=10, latent_dim = 64)\n",
    "# mf.train(utils.common.load_dataset(utils.common.movie_lens, 'train'), utils.common.movie_lens['train']['records'])\n",
    "\n",
    "bpr = models.BPR.BPR(utils.common.movie_lens['user'], utils.common.movie_lens['dimensions'], epochs=5, latent_dim = 32, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 Loss at step 1610: 0.2968\n",
      "Epoch #1 Loss at step 1610: 0.2310\n",
      "Epoch #2 Loss at step 1610: 0.1927\n",
      "Epoch #3 Loss at step 1610: 0.1764\n",
      "Epoch #4 Loss at step 1610: 0.1552\n"
     ]
    }
   ],
   "source": [
    "bpr.batch_size = 8092\n",
    "bpr.train(utils.common.load_dataset(utils.common.movie_lens, 'train'), utils.common.movie_lens['train']['records'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch nr 1 predicted\n",
      "Batch nr 2 predicted\n",
      "Batch nr 3 predicted\n",
      "Batch nr 4 predicted\n",
      "Batch nr 5 predicted\n",
      "Batch nr 6 predicted\n",
      "Batch nr 7 predicted\n",
      "Batch nr 8 predicted\n",
      "Batch nr 9 predicted\n",
      "Batch nr 10 predicted\n",
      "Batch nr 11 predicted\n",
      "Batch nr 12 predicted\n",
      "Batch nr 13 predicted\n",
      "Batch nr 14 predicted\n",
      "Batch nr 15 predicted\n",
      "Batch nr 16 predicted\n",
      "Batch nr 17 predicted\n",
      "Batch nr 18 predicted\n",
      "Batch nr 19 predicted\n",
      "Batch nr 20 predicted\n",
      "Batch nr 21 predicted\n",
      "Batch nr 22 predicted\n",
      "Batch nr 23 predicted\n",
      "Batch nr 24 predicted\n",
      "Batch nr 25 predicted\n",
      "Batch nr 26 predicted\n",
      "Batch nr 27 predicted\n",
      "Batch nr 28 predicted\n",
      "Batch nr 29 predicted\n",
      "Batch nr 30 predicted\n",
      "Batch nr 31 predicted\n",
      "Batch nr 32 predicted\n",
      "Batch nr 33 predicted\n",
      "Batch nr 34 predicted\n",
      "Batch nr 35 predicted\n",
      "Batch nr 36 predicted\n",
      "Batch nr 37 predicted\n",
      "Batch nr 38 predicted\n",
      "Batch nr 39 predicted\n",
      "Batch nr 40 predicted\n",
      "Batch nr 41 predicted\n",
      "Batch nr 42 predicted\n",
      "Batch nr 43 predicted\n",
      "Batch nr 44 predicted\n",
      "Batch nr 45 predicted\n",
      "Batch nr 46 predicted\n",
      "Batch nr 47 predicted\n",
      "Batch nr 48 predicted\n",
      "Batch nr 49 predicted\n",
      "Batch nr 50 predicted\n",
      "Batch nr 51 predicted\n",
      "Batch nr 52 predicted\n",
      "Batch nr 53 predicted\n",
      "Batch nr 54 predicted\n",
      "Batch nr 55 predicted\n",
      "Batch nr 56 predicted\n",
      "Batch nr 57 predicted\n",
      "Batch nr 58 predicted\n",
      "Batch nr 59 predicted\n",
      "Batch nr 60 predicted\n",
      "Batch nr 61 predicted\n",
      "Batch nr 62 predicted\n",
      "Batch nr 63 predicted\n",
      "Batch nr 64 predicted\n",
      "Batch nr 65 predicted\n",
      "Batch nr 66 predicted\n",
      "Batch nr 67 predicted\n",
      "Batch nr 68 predicted\n",
      "Batch nr 69 predicted\n",
      "Batch nr 70 predicted\n",
      "Batch nr 71 predicted\n",
      "Batch nr 72 predicted\n",
      "Batch nr 73 predicted\n",
      "Batch nr 74 predicted\n",
      "Batch nr 75 predicted\n",
      "Batch nr 76 predicted\n",
      "Batch nr 77 predicted\n",
      "Batch nr 78 predicted\n",
      "Batch nr 79 predicted\n",
      "Batch nr 80 predicted\n",
      "Batch nr 81 predicted\n",
      "Batch nr 82 predicted\n",
      "Batch nr 83 predicted\n",
      "Batch nr 84 predicted\n",
      "Batch nr 85 predicted\n",
      "Batch nr 86 predicted\n",
      "Batch nr 87 predicted\n",
      "Batch nr 88 predicted\n",
      "Batch nr 89 predicted\n",
      "Batch nr 90 predicted\n",
      "Batch nr 91 predicted\n",
      "Batch nr 92 predicted\n",
      "Batch nr 93 predicted\n",
      "Batch nr 94 predicted\n",
      "Batch nr 95 predicted\n",
      "Batch nr 96 predicted\n",
      "Batch nr 97 predicted\n",
      "Batch nr 98 predicted\n",
      "Batch nr 99 predicted\n",
      "Batch nr 100 predicted\n",
      "Batch nr 101 predicted\n",
      "Batch nr 102 predicted\n",
      "Batch nr 103 predicted\n",
      "Batch nr 104 predicted\n",
      "Batch nr 105 predicted\n",
      "Batch nr 106 predicted\n",
      "Batch nr 107 predicted\n",
      "Batch nr 108 predicted\n",
      "Batch nr 109 predicted\n",
      "Batch nr 110 predicted\n",
      "Batch nr 111 predicted\n",
      "Batch nr 112 predicted\n",
      "Batch nr 113 predicted\n",
      "Batch nr 114 predicted\n",
      "Batch nr 115 predicted\n",
      "Batch nr 116 predicted\n",
      "Batch nr 117 predicted\n",
      "Batch nr 118 predicted\n",
      "Batch nr 119 predicted\n",
      "Batch nr 120 predicted\n",
      "Batch nr 121 predicted\n",
      "Batch nr 122 predicted\n",
      "Batch nr 123 predicted\n",
      "Batch nr 124 predicted\n",
      "Batch nr 125 predicted\n",
      "Batch nr 126 predicted\n",
      "Batch nr 127 predicted\n",
      "Batch nr 128 predicted\n",
      "Batch nr 129 predicted\n",
      "Batch nr 130 predicted\n",
      "Batch nr 131 predicted\n",
      "Batch nr 132 predicted\n",
      "Batch nr 133 predicted\n",
      "Batch nr 134 predicted\n",
      "Batch nr 135 predicted\n",
      "Batch nr 136 predicted\n",
      "Batch nr 137 predicted\n",
      "Batch nr 138 predicted\n",
      "Batch nr 139 predicted\n",
      "Batch nr 140 predicted\n",
      "Batch nr 141 predicted\n",
      "Batch nr 142 predicted\n",
      "Batch nr 143 predicted\n",
      "Batch nr 144 predicted\n",
      "Batch nr 145 predicted\n",
      "Batch nr 146 predicted\n",
      "Batch nr 147 predicted\n",
      "Batch nr 148 predicted\n",
      "Batch nr 149 predicted\n",
      "Batch nr 150 predicted\n",
      "Batch nr 151 predicted\n",
      "Batch nr 152 predicted\n",
      "Batch nr 153 predicted\n",
      "Batch nr 154 predicted\n",
      "Batch nr 155 predicted\n",
      "Batch nr 156 predicted\n",
      "Batch nr 157 predicted\n",
      "Batch nr 158 predicted\n",
      "Batch nr 159 predicted\n",
      "Batch nr 160 predicted\n",
      "Batch nr 161 predicted\n",
      "Batch nr 162 predicted\n",
      "Batch nr 163 predicted\n",
      "Batch nr 164 predicted\n",
      "Batch nr 165 predicted\n",
      "Batch nr 166 predicted\n",
      "Batch nr 167 predicted\n",
      "Batch nr 168 predicted\n",
      "Batch nr 169 predicted\n",
      "Batch nr 170 predicted\n",
      "Batch nr 171 predicted\n",
      "Batch nr 172 predicted\n",
      "Batch nr 173 predicted\n",
      "Batch nr 174 predicted\n",
      "Batch nr 175 predicted\n",
      "Batch nr 176 predicted\n",
      "Batch nr 177 predicted\n",
      "Batch nr 178 predicted\n",
      "Batch nr 179 predicted\n",
      "Batch nr 180 predicted\n",
      "Batch nr 181 predicted\n",
      "Batch nr 182 predicted\n",
      "Batch nr 183 predicted\n",
      "Batch nr 184 predicted\n",
      "Batch nr 185 predicted\n",
      "Batch nr 186 predicted\n",
      "Batch nr 187 predicted\n",
      "Batch nr 188 predicted\n",
      "Batch nr 189 predicted\n",
      "Batch nr 190 predicted\n",
      "Batch nr 191 predicted\n",
      "Batch nr 192 predicted\n",
      "Batch nr 193 predicted\n",
      "Batch nr 194 predicted\n",
      "Batch nr 195 predicted\n",
      "Batch nr 196 predicted\n",
      "Batch nr 197 predicted\n",
      "Batch nr 198 predicted\n",
      "Batch nr 199 predicted\n",
      "Batch nr 200 predicted\n",
      "Batch nr 201 predicted\n",
      "Batch nr 202 predicted\n",
      "Batch nr 203 predicted\n",
      "Batch nr 204 predicted\n",
      "Batch nr 205 predicted\n",
      "Batch nr 206 predicted\n",
      "Batch nr 207 predicted\n",
      "Batch nr 208 predicted\n",
      "Batch nr 209 predicted\n",
      "Batch nr 210 predicted\n",
      "Batch nr 211 predicted\n",
      "Batch nr 212 predicted\n",
      "Batch nr 213 predicted\n",
      "Batch nr 214 predicted\n",
      "waiting for queue\n",
      "processing results\n",
      "Evaluating BPR |======================================>---------------------| 63.6% \r"
     ]
    }
   ],
   "source": [
    "result = ev.evaluate(bpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.24272472285478736,\n",
       " 'precision': 0.5270423815721148,\n",
       " 'recall': 0.20473174005475447,\n",
       " 'map@1': 0.0009856892523364485,\n",
       " 'map@5': 0.0005072141906801659,\n",
       " 'map@10': 0.0003713081562453642,\n",
       " 'diversity@5': 0.24208009880360445,\n",
       " 'diversity@10': 0.24206584267840847,\n",
       " 'epc@5': 0.6275318828936683,\n",
       " 'epc@10': 0.6274940655597349,\n",
       " 'epd@5': 0.24108397364521375,\n",
       " 'name': 'BPR',\n",
       " 'latent_dim': 32,\n",
       " 'epochs': 5,\n",
       " 'batch_size': 1024}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ConstraintAutoRec |============================================================>| 100.0% \n",
      "Evaluating BPR |============================================================>| 100.0% \n"
     ]
    }
   ],
   "source": [
    "result = ev.evaluate_models([model, bpr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.evaluate_models(nov_models2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4768148516836452,\n",
       " 'precision': 0.5390853520053073,\n",
       " 'recall': 0.5404514802406271,\n",
       " 'map@1': 0.09876236497147713,\n",
       " 'map@5': 0.055156317693372335,\n",
       " 'map@10': 0.043819520386634364,\n",
       " 'diversity@5': 0.16117022541419124,\n",
       " 'diversity@10': 0.16641964375980106,\n",
       " 'epc@5': 0.4180729404503865,\n",
       " 'epc@10': 0.42959490156137525,\n",
       " 'epd@5': 0.2049803661056044,\n",
       " 'name': 'BPR',\n",
       " 'latent_dim': 32,\n",
       " 'epochs': 5,\n",
       " 'batch_size': 8092}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
